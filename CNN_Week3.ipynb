{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":658267,"sourceType":"datasetVersion","datasetId":277323}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# 1. Setup Device\n# Ensure this prints 'cuda' for GPU acceleration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Hyperparameters\nBATCH_SIZE = 32","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-04T20:30:00.178207Z","iopub.execute_input":"2026-01-04T20:30:00.178961Z","iopub.status.idle":"2026-01-04T20:30:07.137835Z","shell.execute_reply.started":"2026-01-04T20:30:00.178929Z","shell.execute_reply":"2026-01-04T20:30:07.137056Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Define the Augmentation Pipeline (Train)\ntrain_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(p=0.5),      # Flip: \"Is the leaf facing left or right?\"\n    transforms.RandomRotation(15),               # Rotate: \"Is the photo taken at an angle?\"\n    transforms.RandomAffine(degrees=0, scale=(0.8, 1.2)), # Zoom: Scale between 80% and 120%\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                         std=[0.229, 0.224, 0.225])\n])\n\n# 2. Define the Clean Pipeline (Validation)\n# No flipping/zooming for validation - we want to test on \"real\" standard images\nval_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                         std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T20:30:11.435288Z","iopub.execute_input":"2026-01-04T20:30:11.435917Z","iopub.status.idle":"2026-01-04T20:30:11.441760Z","shell.execute_reply.started":"2026-01-04T20:30:11.435887Z","shell.execute_reply":"2026-01-04T20:30:11.440883Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_dir = '/kaggle/input/plantvillage-dataset/color'\n\n# 1. Load the dataset (initially with basic transforms just to get the list)\nfull_dataset = datasets.ImageFolder(root=data_dir, transform=val_transforms)\n\n# 2. Calculate lengths\ntrain_size = int(0.8 * len(full_dataset))\nval_size = len(full_dataset) - train_size\n\n# 3. Split the dataset\ntrain_subset, val_subset = random_split(full_dataset, [train_size, val_size])\n\n# 4. OVERRIDE the transforms for the subsets\n# This tells PyTorch: \"When you pull an image from train_subset, apply the Augmentation.\"\ntrain_subset.dataset.transform = train_transforms \nval_subset.dataset.transform = val_transforms\n\n# Verify\nprint(f\"Training Set: {len(train_subset)} images (With Augmentation)\")\nprint(f\"Validation Set: {len(val_subset)} images (Clean)\")\nprint(f\"Number of Classes: {len(full_dataset.classes)}\")\n\n# Save class names for later\nclass_names = full_dataset.classes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T20:33:41.487628Z","iopub.execute_input":"2026-01-04T20:33:41.488003Z","iopub.status.idle":"2026-01-04T20:33:52.864254Z","shell.execute_reply.started":"2026-01-04T20:33:41.487955Z","shell.execute_reply":"2026-01-04T20:33:52.863465Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T20:34:05.635974Z","iopub.execute_input":"2026-01-04T20:34:05.636717Z","iopub.status.idle":"2026-01-04T20:34:05.640421Z","shell.execute_reply.started":"2026-01-04T20:34:05.636689Z","shell.execute_reply":"2026-01-04T20:34:05.639766Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def imshow(img, title):\n    # Un-normalize for visualization\n    img = img.cpu().numpy().transpose((1, 2, 0)) # Move to CPU for plotting\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    img = std * img + mean\n    img = np.clip(img, 0, 1)\n    plt.imshow(img)\n    plt.title(title)\n    plt.axis('off')\n\n# Get a batch of training data\ndataiter = iter(train_loader)\nimages, labels = next(dataiter)\n\n# Show a grid of images\nplt.figure(figsize=(15, 5))\nfor i in range(5):\n    plt.subplot(1, 5, i+1)\n    imshow(images[i], class_names[labels[i]])\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T20:34:11.421117Z","iopub.execute_input":"2026-01-04T20:34:11.421401Z","iopub.status.idle":"2026-01-04T20:34:12.109559Z","shell.execute_reply.started":"2026-01-04T20:34:11.421376Z","shell.execute_reply":"2026-01-04T20:34:12.108540Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_classes=len(class_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T20:34:15.741324Z","iopub.execute_input":"2026-01-04T20:34:15.741672Z","iopub.status.idle":"2026-01-04T20:34:15.746105Z","shell.execute_reply.started":"2026-01-04T20:34:15.741632Z","shell.execute_reply":"2026-01-04T20:34:15.745442Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SimpleCNN(nn.Module):\n    def __init__(self, num_classes):\n        super(SimpleCNN, self).__init__()\n        \n        # --- Block 1 (As per Pseudocode) ---\n        # Conv -> ReLU -> MaxPool\n        # We reduce filters to 16 to limit learning capacity\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n        self.relu1 = nn.ReLU()\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        # --- Block 2 (As per Pseudocode) ---\n        # Conv -> ReLU -> MaxPool\n        # We reduce filters to 32\n        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n        self.relu2 = nn.ReLU()\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        # --- Classification Head ---\n        self.flatten = nn.Flatten()\n        \n        # Calculate input size: \n        # Image 224 -> Pool 1 -> 112 -> Pool 2 -> 56\n        # Final Feature Map: 32 channels * 56 * 56\n        self.fc = nn.Linear(32 * 56 * 56, num_classes) \n        # Note: No intermediate dense layer (512) and NO DROPOUT.\n        # Direct connection to output helps simulate \"naive\" learning.\n\n    def forward(self, x):\n        x = self.pool1(self.relu1(self.conv1(x)))\n        x = self.pool2(self.relu2(self.conv2(x)))\n        \n        x = self.flatten(x)\n        x = self.fc(x)\n        return x\n\n# Instantiate the stricter, simpler model\nsimple_model = SimpleCNN(num_classes).to(device)\nprint(\"SimpleCNN initialized.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T20:34:31.637513Z","iopub.execute_input":"2026-01-04T20:34:31.638326Z","iopub.status.idle":"2026-01-04T20:34:31.865095Z","shell.execute_reply.started":"2026-01-04T20:34:31.638295Z","shell.execute_reply":"2026-01-04T20:34:31.864459Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n    train_losses, val_losses = [], []\n    train_accuracies, val_accuracies = [], []\n\n    for epoch in range(epochs):\n        print(f\"Epoch {epoch+1}/{epochs}\")\n        print(\"-\" * 10)\n\n        # --- Training ---\n        model.train()\n        running_loss = 0.0\n        correct_train = 0\n        total_train = 0\n\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item() * images.size(0)\n            _, predicted = torch.max(outputs, 1)\n            total_train += labels.size(0)\n            correct_train += (predicted == labels).sum().item()\n\n        epoch_loss = running_loss / len(train_loader.dataset)\n        epoch_acc = correct_train / total_train\n        train_losses.append(epoch_loss)\n        train_accuracies.append(epoch_acc)\n\n        # --- Validation ---\n        model.eval()\n        val_loss = 0.0\n        correct_val = 0\n        total_val = 0\n\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                \n                outputs = model(images)\n                loss = criterion(outputs, labels)\n\n                val_loss += loss.item() * images.size(0)\n                _, predicted = torch.max(outputs, 1)\n                total_val += labels.size(0)\n                correct_val += (predicted == labels).sum().item()\n\n        epoch_val_loss = val_loss / len(val_loader.dataset)\n        epoch_val_acc = correct_val / total_val\n        val_losses.append(epoch_val_loss)\n        val_accuracies.append(epoch_val_acc)\n\n        print(f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n        print(f\"Val Loss: {epoch_val_loss:.4f} Acc: {epoch_val_acc:.4f}\")\n\n    return train_losses, val_losses, train_accuracies, val_accuracies","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T20:34:40.981318Z","iopub.execute_input":"2026-01-04T20:34:40.981629Z","iopub.status.idle":"2026-01-04T20:34:40.991014Z","shell.execute_reply.started":"2026-01-04T20:34:40.981602Z","shell.execute_reply":"2026-01-04T20:34:40.990245Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(simple_model.parameters(), lr=0.001)\n\n# Run for 10 epochs\nhistory = train_model(simple_model, train_loader, val_loader, criterion, optimizer, epochs=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T20:34:56.824563Z","iopub.execute_input":"2026-01-04T20:34:56.825276Z","iopub.status.idle":"2026-01-04T20:53:55.948966Z","shell.execute_reply.started":"2026-01-04T20:34:56.825246Z","shell.execute_reply":"2026-01-04T20:53:55.948210Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting the Training vs Validation Curves\nepochs_range = range(1, 11)\n\nplt.figure(figsize=(12, 4))\n\n# Subplot 1: Accuracy\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, history[2], label='Training Accuracy') # history[2] is train_acc\nplt.plot(epochs_range, history[3], label='Validation Accuracy') # history[3] is val_acc\nplt.title('Accuracy: Training vs Validation')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\n\n# Subplot 2: Loss\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, history[0], label='Training Loss') # history[0] is train_loss\nplt.plot(epochs_range, history[1], label='Validation Loss') # history[1] is val_loss\nplt.title('Loss: Training vs Validation')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(loc='upper right')\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T20:54:44.635814Z","iopub.execute_input":"2026-01-04T20:54:44.636371Z","iopub.status.idle":"2026-01-04T20:54:44.856037Z","shell.execute_reply.started":"2026-01-04T20:54:44.636343Z","shell.execute_reply":"2026-01-04T20:54:44.855323Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision import models\n\n# 1. Load the Pretrained MobileNetV2\n# weights=\"DEFAULT\" downloads the best available ImageNet weights\ntransfer_model = models.mobilenet_v2(weights=\"DEFAULT\")\n\n# 2. Freeze the Backbone\n# Loop through all parameters and lock them\nfor param in transfer_model.parameters():\n    param.requires_grad = False\n\n# 3. Modify the Head (The Classifier)\n# In MobileNetV2, the classifier is a linear layer at index [1]\n# We replace it with a new Linear layer: Input (1280) -> Output (Your Classes)\nnum_ftrs = transfer_model.classifier[1].in_features\n# We reuse 'num_classes' calculated earlier\ntransfer_model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n\n# Move the model to the GPU\ntransfer_model = transfer_model.to(device)\n\nprint(\"Transfer Learning Model Initialized.\")\nprint(\"Backbone: Frozen (MobileNetV2)\")\nprint(f\"Head: Replaced (Linear {num_ftrs} -> {num_classes})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T20:54:47.754757Z","iopub.execute_input":"2026-01-04T20:54:47.755498Z","iopub.status.idle":"2026-01-04T20:54:48.119361Z","shell.execute_reply.started":"2026-01-04T20:54:47.755446Z","shell.execute_reply":"2026-01-04T20:54:48.118675Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# We need a new optimizer that ONLY updates the parameters we didn't freeze!\nparams_to_update = []\nfor name, param in transfer_model.named_parameters():\n    if param.requires_grad == True:\n        params_to_update.append(param)\n\n# Setup Optimizer for ONLY the classifier head\noptimizer_transfer = optim.Adam(params_to_update, lr=0.001)\n\n# Reuse the same Loss Function\ncriterion = nn.CrossEntropyLoss()\n\nprint(\"Starting Transfer Learning (5 Epochs)...\")\ntransfer_history = train_model(transfer_model, train_loader, val_loader, criterion, optimizer_transfer, epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T20:54:53.646613Z","iopub.execute_input":"2026-01-04T20:54:53.646912Z","iopub.status.idle":"2026-01-04T21:04:05.179271Z","shell.execute_reply.started":"2026-01-04T20:54:53.646885Z","shell.execute_reply":"2026-01-04T21:04:05.178519Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting the Transfer Learning Curves\nepochs_range = range(1, 6) # We only ran 5 epochs\n\nplt.figure(figsize=(12, 4))\n\n# Subplot 1: Accuracy\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, transfer_history[2], label='Training Accuracy') # transfer_history[2] is train_acc\nplt.plot(epochs_range, transfer_history[3], label='Validation Accuracy') # transfer_history[3] is val_acc\nplt.title('Transfer Learning Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\n\n# Subplot 2: Loss\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, transfer_history[0], label='Training Loss') # transfer_history[0] is train_loss\nplt.plot(epochs_range, transfer_history[1], label='Validation Loss') # transfer_history[1] is val_loss\nplt.title('Transfer Learning Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(loc='upper right')\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T21:04:36.741818Z","iopub.execute_input":"2026-01-04T21:04:36.742149Z","iopub.status.idle":"2026-01-04T21:04:37.208913Z","shell.execute_reply.started":"2026-01-04T21:04:36.742118Z","shell.execute_reply":"2026-01-04T21:04:37.208206Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport pandas as pd\n\n# 1. Switch model to evaluation mode\ntransfer_model.eval()\nall_preds = []\nall_labels = []\n\n# 2. Get predictions for the entire validation set\nprint(\"Generating predictions...\")\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        outputs = transfer_model(images)\n        _, preds = torch.max(outputs, 1)\n        \n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# 3. Generate the Classification Report\nprint(\"üèÜ FINAL TRANSFER LEARNING REPORT üèÜ\")\nprint(\"========================================\")\n# Get class names from the dataset\ntarget_names = full_dataset.classes\nreport = classification_report(all_labels, all_preds, target_names=target_names)\nprint(report)\n\n# 4. Generate Confusion Matrix Plot\nplt.figure(figsize=(20, 15)) # Make it big!\ncm = confusion_matrix(all_labels, all_preds)\nsns.heatmap(cm, annot=False, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\nplt.title(\"Confusion Matrix: MobileNetV2 Transfer Learning\")\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.xticks(rotation=90)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T21:04:41.467284Z","iopub.execute_input":"2026-01-04T21:04:41.467618Z","iopub.status.idle":"2026-01-04T21:05:05.626629Z","shell.execute_reply.started":"2026-01-04T21:04:41.467591Z","shell.execute_reply":"2026-01-04T21:05:05.625789Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the trained model\ntorch.save(transfer_model.state_dict(), 'plant_disease_mobilenet_97acc.pth')\n\nprint(\"Model saved successfully as 'plant_disease_mobilenet_97acc.pth'\")\nprint(\"Week 3: MISSION ACCOMPLISHED.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T21:05:05.627948Z","iopub.execute_input":"2026-01-04T21:05:05.628342Z","iopub.status.idle":"2026-01-04T21:05:05.667959Z","shell.execute_reply.started":"2026-01-04T21:05:05.628315Z","shell.execute_reply":"2026-01-04T21:05:05.667197Z"}},"outputs":[],"execution_count":null}]}