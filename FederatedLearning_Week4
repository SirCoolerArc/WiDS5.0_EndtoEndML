{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":658267,"sourceType":"datasetVersion","datasetId":277323}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import subprocess\nimport sys\nimport os\n\n# Filter unrelated warnings before they even start\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\" # Silence TensorFlow/XLA\nos.environ[\"RAY_DEDUP_LOGS\"] = \"0\"       # Silence Ray deduplication\n\nprint(\"üì¶ Installing Flower (Quietly)...\")\ntry:\n    import flwr\nexcept ImportError:\n    # The '-q' flag keeps it silent\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"flwr\", \"-q\"])\n    print(\"‚úÖ Flower Installed Successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T21:31:46.000489Z","iopub.execute_input":"2026-01-13T21:31:46.000804Z","iopub.status.idle":"2026-01-13T21:31:55.791516Z","shell.execute_reply.started":"2026-01-13T21:31:46.000781Z","shell.execute_reply":"2026-01-13T21:31:55.790857Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\nimport logging\nimport collections\nfrom typing import List, Tuple\n\n# 1. Silence Python Warnings\nwarnings.filterwarnings(\"ignore\")\n\n# 2. Silence Internal Loggers (Ray, Flower, Distutils)\nlogging.getLogger(\"flwr\").setLevel(logging.ERROR)\nlogging.getLogger(\"ray\").setLevel(logging.ERROR)\nlogging.getLogger(\"std\").setLevel(logging.ERROR)\n\n# 3. Standard Imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport flwr as fl\nfrom flwr.common import Context, Metrics\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, random_split\nimport matplotlib.pyplot as plt\n\n# 4. Device Setup\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"‚úÖ Setup Complete.\")\nprint(f\"   - Device: {DEVICE}\")\nprint(f\"   - Logs:   Suppressed (Clean Mode)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T21:34:02.437970Z","iopub.execute_input":"2026-01-13T21:34:02.438281Z","iopub.status.idle":"2026-01-13T21:34:09.053760Z","shell.execute_reply.started":"2026-01-13T21:34:02.438256Z","shell.execute_reply":"2026-01-13T21:34:09.053057Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"‚è≥ Loading and Splitting Data...\")\n\n# 1. Define Transforms (MobileNetV2 requires 224x224 input)\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# 2. Load the Dataset\ndataset_path = '/kaggle/input/plantvillage-dataset/color'\nif not os.path.exists(dataset_path):\n    raise FileNotFoundError(f\"‚ùå Dataset not found at {dataset_path}. Please check inputs.\")\n\nfull_dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n\n# 3. Split into 3 Clients\ntotal_size = len(full_dataset)\nsplit_size = total_size // 3\nremainder = total_size - (split_size * 3)\n\n# Random split ensures IID data distribution\npart1, part2, part3 = random_split(full_dataset, [split_size, split_size, split_size + remainder])\n\n# 4. Create DataLoaders\nBATCH_SIZE = 32\ntrain_loaders = [\n    DataLoader(part1, batch_size=BATCH_SIZE, shuffle=True),\n    DataLoader(part2, batch_size=BATCH_SIZE, shuffle=True),\n    DataLoader(part3, batch_size=BATCH_SIZE, shuffle=True)\n]\nval_loaders = [\n    DataLoader(part1, batch_size=BATCH_SIZE, shuffle=False),\n    DataLoader(part2, batch_size=BATCH_SIZE, shuffle=False),\n    DataLoader(part3, batch_size=BATCH_SIZE, shuffle=False)\n]\n\nprint(f\"‚úÖ Data Preparation Complete.\")\nprint(f\"   - Total Images: {total_size}\")\nprint(f\"   - Clients: 3 (approx {len(part1)} images each)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T21:34:12.704978Z","iopub.execute_input":"2026-01-13T21:34:12.705385Z","iopub.status.idle":"2026-01-13T21:35:14.056410Z","shell.execute_reply.started":"2026-01-13T21:34:12.705362Z","shell.execute_reply":"2026-01-13T21:35:14.055593Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 1. Define Model Architecture ---\nclass PlantVillageModel(nn.Module):\n    def __init__(self, num_classes=38):\n        super(PlantVillageModel, self).__init__()\n        # Load pre-trained MobileNetV2\n        self.base_model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n        \n        # Freeze base layers (Transfer Learning)\n        for param in self.base_model.parameters():\n            param.requires_grad = False\n            \n        # Replace classifier head\n        self.base_model.classifier[1] = nn.Linear(1280, num_classes)\n\n    def forward(self, x):\n        return self.base_model(x)\n\n# --- 2. Define The Federated Client ---\nclass PlantVillageClient(fl.client.NumPyClient):\n    def __init__(self, net, train_loader, val_loader):\n        self.net = net\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n\n    def get_parameters(self, config):\n        return [val.cpu().numpy() for _, val in self.net.state_dict().items()]\n\n    def set_parameters(self, parameters):\n        # We use a local import to ensure Ray workers always find 'collections'\n        import collections \n        params_dict = zip(self.net.state_dict().keys(), parameters)\n        state_dict = collections.OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n        self.net.load_state_dict(state_dict, strict=True)\n\n    def fit(self, parameters, config):\n        self.set_parameters(parameters)\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.Adam(self.net.parameters(), lr=0.001)\n        \n        # Local Training (The \"Secret\" Training)\n        self.net.train()\n        for images, labels in self.train_loader:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            optimizer.zero_grad()\n            output = self.net(images)\n            loss = criterion(output, labels)\n            loss.backward()\n            optimizer.step()\n            \n        return self.get_parameters(config={}), len(self.train_loader.dataset), {}\n\n    def evaluate(self, parameters, config):\n        self.set_parameters(parameters)\n        self.net.eval()\n        correct = 0\n        total = 0\n        loss = 0.0\n        criterion = nn.CrossEntropyLoss()\n        \n        # Local Evaluation\n        with torch.no_grad():\n            for images, labels in self.val_loader:\n                images, labels = images.to(DEVICE), labels.to(DEVICE)\n                outputs = self.net(images)\n                loss += criterion(outputs, labels).item()\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        accuracy = correct / total\n        return float(loss), len(self.val_loader.dataset), {\"accuracy\": float(accuracy)}\n\nprint(\"‚úÖ Model & Client Classes Defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T21:36:01.851062Z","iopub.execute_input":"2026-01-13T21:36:01.851346Z","iopub.status.idle":"2026-01-13T21:36:01.864162Z","shell.execute_reply.started":"2026-01-13T21:36:01.851322Z","shell.execute_reply":"2026-01-13T21:36:01.863381Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 1. Client Generator Function ---\n# Note: Uses 'context' signature to prevent Deprecation Warnings\ndef client_fn(context: Context):\n    # Retrieve partition ID (0, 1, or 2)\n    partition_id = context.node_config[\"partition-id\"]\n    loader_idx = int(partition_id)\n    \n    # Initialize Model & Client\n    net = PlantVillageModel().to(DEVICE)\n    client = PlantVillageClient(net, train_loaders[loader_idx], val_loaders[loader_idx])\n    \n    # Return as Client\n    return client.to_client()\n\n# --- 2. Aggregation Strategy (The \"Speedometer\") ---\ndef weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n    # Multiply accuracy of each client by number of examples used\n    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n    examples = [num_examples for num_examples, _ in metrics]\n    \n    # Aggregate and return custom metric (weighted average)\n    return {\"accuracy\": sum(accuracies) / sum(examples)}\n\nstrategy = fl.server.strategy.FedAvg(\n    evaluate_metrics_aggregation_fn=weighted_average,\n)\n\n# --- 3. Resource Allocation ---\n# Grant GPU access to avoid \"No CUDA\" errors\nclient_resources = {\"num_cpus\": 1, \"num_gpus\": 0.5}\n\nprint(\"‚úÖ Simulation Driver Ready.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T21:36:12.702707Z","iopub.execute_input":"2026-01-13T21:36:12.702998Z","iopub.status.idle":"2026-01-13T21:36:12.709672Z","shell.execute_reply.started":"2026-01-13T21:36:12.702974Z","shell.execute_reply":"2026-01-13T21:36:12.708902Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"üöÄ Starting Federated Simulation (3 Rounds)...\")\n\n# Start Simulation\nhist = fl.simulation.start_simulation(\n    client_fn=client_fn,\n    num_clients=3,\n    config=fl.server.ServerConfig(num_rounds=3),\n    strategy=strategy,\n    client_resources=client_resources, \n)\n\nprint(\"\\n‚úÖ Simulation Complete.\")\n\n# Extract Accuracy\nrounds, acc = zip(*hist.metrics_distributed[\"accuracy\"])\nfinal_acc = acc[-1] * 100\n\n# Plot\nplt.figure(figsize=(10, 6))\nplt.plot(rounds, acc, marker='o', color='#2ca02c', linewidth=2, markersize=8)\nplt.title(f\"Federated Learning Accuracy (Final: {final_acc:.2f}%)\", fontsize=14)\nplt.xlabel(\"Communication Round\", fontsize=12)\nplt.ylabel(\"Accuracy\", fontsize=12)\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.xticks(rounds)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T21:36:20.211546Z","iopub.execute_input":"2026-01-13T21:36:20.211845Z","iopub.status.idle":"2026-01-13T21:46:14.166200Z","shell.execute_reply.started":"2026-01-13T21:36:20.211821Z","shell.execute_reply":"2026-01-13T21:46:14.165515Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==============================================================================\n# FINAL PROJECT REPORT: WEEK 4\n# ==============================================================================\n\n# 1. Define Baselines (Your Week 3 Result)\nWEEK_3_ACCURACY = 0.9734  # 97% Baseline\nTHRESHOLD = 0.05        # 5% Acceptable Drop\n\n# 2. Get Week 4 Result\nweek_4_accuracy = acc[-1]\n\n# 3. Print Comparison\nprint(\"-\" * 50)\nprint(f\"üìÑ EXECUTION REPORT\")\nprint(\"-\" * 50)\nprint(f\"Week 3 (Centralized) Accuracy: {WEEK_3_ACCURACY*100:.2f}%\")\nprint(f\"Week 4 (Federated) Accuracy:   {week_4_accuracy*100:.2f}%\")\nprint(\"-\" * 50)\n\n# 4. Success Logic\nif week_4_accuracy > (WEEK_3_ACCURACY - THRESHOLD):\n    print(\"‚úÖ RESULT: System Robust. Deployment Ready.\")\n    print(\"   (Privacy Tax was minimal/acceptable)\")\nelse:\n    print(\"‚ö†Ô∏è RESULT: Drastic Drop Detected.\")\n    print(\"   (Action: Increase Rounds or Epochs)\")\nprint(\"-\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T21:48:52.676789Z","iopub.execute_input":"2026-01-13T21:48:52.677545Z","iopub.status.idle":"2026-01-13T21:48:52.683451Z","shell.execute_reply.started":"2026-01-13T21:48:52.677512Z","shell.execute_reply":"2026-01-13T21:48:52.682673Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}